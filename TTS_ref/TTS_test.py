import os.path

import torch
from TTS.api import TTS

# Get device
device = "cuda" if torch.cuda.is_available() else "cpu"

# List available ğŸ¸TTS models
print(TTS().list_models())

# Init TTS
TTS_model = '/media/zzg/GJ_disk01/pretrained_model/coqui/XTTS-v2'
tts = TTS(model_path=TTS_model, config_path=os.path.join(TTS_model, "config.json"), progress_bar=True).to(device)

# Run TTS
# â— Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language
# Text to speech list of amplitude values as output
# wav = tts.tts(text="æˆ‘æ˜¯è°ï¼Œæˆ‘åœ¨å“ªï¼Œæˆ‘å¹²å•¥å‘¢ï¼Ÿ", speaker_wav="/media/zzg/GJ_disk01/data/AUDIO/XzJosh/audiodataset/åå¥³äºº/badXT/badXT_5.wav", language="zh")
# Text to speech to a file
# tts.tts_to_file(text="æˆ‘æ˜¯è°ï¼Œæˆ‘åœ¨å“ªï¼Œæˆ‘å¹²å•¥å‘¢ï¼Ÿ", speaker_wav="/media/zzg/GJ_disk01/data/AUDIO/XzJosh/audiodataset/åå¥³äºº/badXT/badXT_5.wav", language="zh", file_path="TTS_wav/badgirl.wav")
tts.tts_to_file(text="æˆ‘æ˜¯è°ï¼Œæˆ‘åœ¨å“ªï¼Œæˆ‘å¹²å•¥å‘¢ï¼Ÿ", speaker_wav="/media/zzg/GJ_disk01/data/AUDIO/XzJosh/audiodataset/ä¸çœŸ/dingzhen/dingzhen_4.wav", language="zh", file_path="../TTS_wav/dingzhen.wav")
